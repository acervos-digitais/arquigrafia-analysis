{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection / Captioning / Scene Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "from os import listdir, makedirs, path\n",
    "\n",
    "from PIL import Image as PImage\n",
    "\n",
    "IMAGES_IN_PATH = \"../../imgs/arquigrafia\"\n",
    "\n",
    "OUT_PATH = \"./metadata/objects\"\n",
    "makedirs(OUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJS = {\n",
    "  \"awning\": 0.3,\n",
    "  \"balcony\": 0.2,\n",
    "  \"chair\": 0.2,\n",
    "  \"chimney\": 0.3,\n",
    "  \"door portico\": 0.3,\n",
    "  \"door\": 0.2,\n",
    "  \"masonry\": 0.3,\n",
    "  \"overhang\": 0.3,\n",
    "  \"painting\": 0.4,\n",
    "  \"person\": 0.2,\n",
    "  \"railing\": 0.3,\n",
    "  \"ramp\": 0.3,\n",
    "  \"sculpture\": 0.4,\n",
    "  \"stairs\": 0.2,\n",
    "  \"steps\": 0.2,\n",
    "  \"support arch\": 0.2,\n",
    "  \"support column\": 0.3,\n",
    "  \"table\": 0.2,\n",
    "  \"brick wall\": 0.2,\n",
    "  \"concrete wall\": 0.2,\n",
    "  \"stone wall\": 0.2,\n",
    "  \"window\": 0.2,\n",
    "}\n",
    "\n",
    "OBJS_LABELS = sorted(OBJS.keys())\n",
    "OBJS_THOLDS = [OBJS[k] for k in OBJS_LABELS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, pipeline\n",
    "\n",
    "CAP_MODEL_NAME = \"openbmb/MiniCPM-V-2\"\n",
    "CAP_MODEL_REV = \"187851962daa9b63072d40ec802f597b71bff532\"\n",
    "\n",
    "CAP_COND = [\n",
    "  {'role': 'user', 'content': \"The following image is a picture taken in Brazil.\"},\n",
    "  {'role': 'user', 'content': \"Give a short description of the image.\"},\n",
    "  {'role': 'user', 'content': \"Don't mention sports or winter.\"},\n",
    "]\n",
    "\n",
    "CAP_MODEL = {\n",
    "  \"model\": AutoModel.from_pretrained(CAP_MODEL_NAME, revision=CAP_MODEL_REV, trust_remote_code=True, torch_dtype=torch.bfloat16).to(\"cuda\", dtype=torch.bfloat16),\n",
    "  \"pre\": AutoTokenizer.from_pretrained(CAP_MODEL_NAME, revision=CAP_MODEL_REV, trust_remote_code=True),\n",
    "  \"chat\": CAP_COND\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENPT_MODEL_NAME = \"Helsinki-NLP/opus-mt-tc-big-en-pt\"\n",
    "ENPT_PIPELINE = pipeline(model=ENPT_MODEL_NAME, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_caption(img, model):\n",
    "  caption, _, _ = model[\"model\"].chat(\n",
    "    image=img,\n",
    "    msgs=model[\"chat\"],\n",
    "    max_length=32,\n",
    "    context=None,\n",
    "    tokenizer=model[\"pre\"],\n",
    "    sampling=True,\n",
    "    temperature=0.1\n",
    "  )\n",
    "  caption = caption[:caption.find(\".\") + 1]\n",
    "  caption = caption[:caption.find(\", possibly\")]\n",
    "  return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Owlv2Processor, Owlv2ForObjectDetection\n",
    "\n",
    "OBJ_TARGET_SIZE = torch.Tensor([500, 500])\n",
    "OBJ_MODEL = \"google/owlv2-base-patch16-ensemble\"\n",
    "\n",
    "obj_model = Owlv2ForObjectDetection.from_pretrained(OBJ_MODEL).to(\"cuda\")\n",
    "obj_processor = Owlv2Processor.from_pretrained(OBJ_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_px_to_pct(box, img_w, img_h, model_dims):\n",
    "  scale_factor = torch.tensor([max(img_w, img_h) / img_w , max(img_w, img_h) / img_h])\n",
    "  return [round(x, 4) for x in (box.cpu().reshape(2, -1) / model_dims * scale_factor).reshape(-1).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_object_detection(img, obj_labels, obj_tholds):\n",
    "  input = obj_processor(text=obj_labels, images=img, return_tensors=\"pt\").to(\"cuda\")\n",
    "  with torch.no_grad():\n",
    "    obj_out = obj_model(**input)\n",
    "\n",
    "  res = obj_processor.post_process_object_detection(outputs=obj_out, target_sizes=[OBJ_TARGET_SIZE])\n",
    "  slbs = zip(res[0][\"scores\"], res[0][\"labels\"], res[0][\"boxes\"])\n",
    "  iw, ih = img.size\n",
    "\n",
    "  detected_objs = [{\"label\": obj_labels[l.item()], \"box\": box_px_to_pct(b, iw, ih, OBJ_TARGET_SIZE)} for s,l,b in slbs if s > obj_tholds[l.item()]]\n",
    "\n",
    "  detected_objs_boxes = {}\n",
    "  for o in detected_objs:\n",
    "    ol = o[\"label\"]\n",
    "    detected_objs_boxes[ol] = detected_objs_boxes.get(ol, []) + [o[\"box\"]]\n",
    "\n",
    "  return detected_objs_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "input_files = sorted([f for f in listdir(IMAGES_IN_PATH) if f.endswith(\"jpg\")])\n",
    "mLangs = [\"en\"]\n",
    "\n",
    "for io_file in input_files[:1]:\n",
    "  input_file_path = path.join(IMAGES_IN_PATH, io_file)\n",
    "  output_file_path = path.join(OUT_PATH, io_file.replace(\".jpg\", \".json\"))\n",
    "\n",
    "  if path.isfile(output_file_path):\n",
    "    continue\n",
    "\n",
    "  print(IMAGES_IN_PATH, io_file)\n",
    "\n",
    "  image = PImage.open(input_file_path).convert(\"RGB\")\n",
    "\n",
    "  image_data = {}\n",
    "  image_data[\"caption\"] = {}\n",
    "  image_data[\"caption\"][\"en\"] = run_caption(image, CAP_MODEL)\n",
    "  image_data[\"caption\"][\"pt\"] = ENPT_PIPELINE(image_data[\"caption\"][\"en\"])[0][\"translation_text\"]\n",
    "  image_data[\"boxes\"] = run_object_detection(image, OBJS_LABELS, OBJS_THOLDS)\n",
    "\n",
    "  with open(output_file_path, \"w\") as of:\n",
    "    json.dump(image_data, of, sort_keys=True, separators=(',',':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Process: Create output json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from os import listdir, path\n",
    "\n",
    "CAPTIONS_PATH = \"./metadata/objects\"\n",
    "IMAGES_DB_FILE_PATH = \"./metadata/images.json\"\n",
    "OBJECTS_DB_FILE_PATH = \"./metadata/objects.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename -> image info\n",
    "img_info = {}\n",
    "\n",
    "# obj name -> image name\n",
    "obj_data = {}\n",
    "\n",
    "input_files = sorted([f for f in listdir(CAPTIONS_PATH) if f.endswith(\"json\")])\n",
    "\n",
    "for io_file in input_files:\n",
    "  input_file_path = path.join(CAPTIONS_PATH, io_file)\n",
    "  with open(input_file_path, \"r\") as f:\n",
    "    id = io_file.replace(\".json\", \"\")\n",
    "    img_info[id] = json.load(f)\n",
    "    for l in img_info[id][\"boxes\"].keys():\n",
    "      obj_data[l] = obj_data.get(l, []) + [id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(IMAGES_DB_FILE_PATH, \"w\") as f:\n",
    "  json.dump(img_info, f, separators=(',',':'), sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OBJECTS_DB_FILE_PATH, \"w\") as f:\n",
    "  json.dump(obj_data, f, separators=(',',':'), sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview json boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from os import path\n",
    "from PIL import Image as PImage, ImageDraw as PImageDraw\n",
    "\n",
    "IMAGES_DB_FILE_PATH = \"./metadata/images.json\"\n",
    "IMAGES_PATH = \"../../imgs/arquigrafia\"\n",
    "\n",
    "with open(IMAGES_DB_FILE_PATH, \"r\") as f:\n",
    "  img_info = json.load(f)\n",
    "\n",
    "for id, d in img_info.items():\n",
    "  img_path = path.join(IMAGES_PATH, d[\"filename\"])\n",
    "  img = PImage.open(img_path).convert(\"RGBA\")\n",
    "  iw,ih = img.size\n",
    "  draw = PImageDraw.Draw(img)\n",
    "  for l, bs in d[\"boxes\"].items():\n",
    "    for x0,y0,x1,y1 in bs:\n",
    "      draw.rectangle(((x0*iw, y0*ih), (x1*iw, y1*ih)), outline=(255, 0, 0))\n",
    "  print(d[\"objects\"], \"\\n\", d[\"caption\"])\n",
    "  display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EN -> PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "PHRASES = [\n",
    "  \"I like to eat rice.\",\n",
    "  \"Tom tried to stab me.\",\n",
    "  \"He has been to Hawaii several times.\",\n",
    "  \"The image features a white house with black trim, windows on the front and side walls.\",\n",
    "  \"This image features a modern, open-concept living space with an eye-catching staircase and various furniture pieces.\",\n",
    "  \"The image depicts an interior space with a staircase, furniture such as chairs and tables.\",\n",
    "  \"The image showcases a modern building with glass walls, concrete stairs leading to it and greenery surrounding the area.\",\n",
    "  \"The image shows a view through glass panes, revealing indoor furniture and plants outside.\",\n",
    "  \"The image is of a modern building with large windows and columns.\"\n",
    "]\n",
    "\n",
    "ENPT_MODEL_NAME = \"Helsinki-NLP/opus-mt-tc-big-en-pt\"\n",
    "ENPT_PIPELINE = pipeline(model=ENPT_MODEL_NAME, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in PHRASES:\n",
    "  print(ENPT_PIPELINE(p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
